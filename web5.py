"""
DeepSeek-OCR Gradio åº”ç”¨ - å®Œæ•´ç‰ˆ
æ”¯æŒåŸå§‹æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹ï¼Œé›†æˆç°ä»£åŒ–UIå’Œå®Œæ•´åŠŸèƒ½
"""

import gradio as gr
import torch
from modelscope import AutoModel, AutoTokenizer
from peft import PeftModel
import os
import tempfile
from PIL import Image, ImageDraw
import re
from typing import Tuple, Optional, Dict, Any, List
import fitz  # PyMuPDF for PDF processing
import numpy as np
import io
import time
import psutil
import GPUtil
import socket

# --- å¸¸é‡å’Œé…ç½® ---
MODEL_CONFIGS = {
    "ğŸ¤– åŸå§‹DeepSeek-OCRæ¨¡å‹": {
        "model_name": "deepseek-ai/DeepSeek-OCR",
        "is_custom": False
    },
    "ğŸ¯ å¾®è°ƒæ¨¡å‹ (LoRA)": {
        "model_name": "deepseek-ai/DeepSeek-OCR",
        "is_custom": True,
        "adapter_path": ".finetuned_model/final_model"  # é»˜è®¤å¾®è°ƒæ¨¡å‹è·¯å¾„
    }
}

MODEL_SIZE_CONFIGS = {
    "ğŸš€ æé€Ÿæ¨¡å¼": {"base_size": 512, "image_size": 512, "crop_mode": False},
    "âš–ï¸ å¹³è¡¡æ¨¡å¼": {"base_size": 640, "image_size": 640, "crop_mode": False},
    "ğŸ¯ ç²¾å‡†æ¨¡å¼": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
    "ğŸ” è¶…æ¸…æ¨¡å¼": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
    "ğŸ¤– Gundamæ¨¡å¼": {"base_size": 1024, "image_size": 640, "crop_mode": True},
}

TASK_PROMPTS = {
    "ğŸ“ è‡ªç”±OCR": "<image>\nè‡ªç”±OCR.",
    "ğŸ“„ è½¬æ¢ä¸ºMarkdown": "<image>\n<|grounding|>å°†æ–‡æ¡£è½¬æ¢ä¸ºmarkdown.",
    "ğŸ“ˆ è§£æå›¾è¡¨": "<image>\nè§£æå›¾è¡¨.",
}

DEFAULT_MODEL_TYPE = "ğŸ¤– åŸå§‹DeepSeek-OCRæ¨¡å‹"
DEFAULT_MODEL_SIZE = "ğŸ¤– Gundamæ¨¡å¼"
DEFAULT_TASK_TYPE = "ğŸ“„ è½¬æ¢ä¸ºMarkdown"
BOUNDING_BOX_PATTERN = re.compile(r"<\|det\|>\[\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]\]<\|/det\|>")
BOUNDING_BOX_COLOR = "#FF6B6B"
BOUNDING_BOX_WIDTH = 3
NORMALIZATION_FACTOR = 1000

# --- å…¨å±€å˜é‡ ---
model = None
tokenizer = None
model_gpu = None
current_model_type = None
current_adapter_path = None


def get_available_port(start_port=7860):
    """è·å–å¯ç”¨çš„ç«¯å£å·"""
    port = start_port
    while True:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
                return port
        except OSError:
            port += 1
            if port > start_port + 100:
                raise Exception("æ‰¾ä¸åˆ°å¯ç”¨ç«¯å£")


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç±»"""

    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.memory_before = None
        self.memory_after = None
        self.gpu_before = None
        self.gpu_after = None

    def start(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.start_time = time.time()
        self.memory_before = self.get_memory_usage()
        self.gpu_before = self.get_gpu_usage()

    def stop(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.end_time = time.time()
        self.memory_after = self.get_memory_usage()
        self.gpu_after = self.get_gpu_usage()

    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': psutil.virtual_memory().percent
        }

    def get_gpu_usage(self) -> Optional[Dict[str, Any]]:
        """è·å–GPUä½¿ç”¨æƒ…å†µ"""
        try:
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu = gpus[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
                return {
                    'load': gpu.load * 100,
                    'memory_used': gpu.memoryUsed,
                    'memory_total': gpu.memoryTotal,
                    'memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100
                }
        except Exception:
            return None
        return None

    def get_performance_report(self, image_count: int = 1) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if self.start_time is None or self.end_time is None:
            return "æ€§èƒ½æ•°æ®ä¸å¯ç”¨"

        total_time = self.end_time - self.start_time
        avg_time_per_image = total_time / image_count if image_count > 0 else total_time

        report_lines = [
            "## ğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Š",
            f"**â±ï¸ å¤„ç†æ—¶é—´**: {total_time:.2f}ç§’",
            f"**ğŸ–¼ï¸ å¤„ç†æ•°é‡**: {image_count}å¼ å›¾åƒ",
            f"**ğŸ“ˆ å¹³å‡é€Ÿåº¦**: {avg_time_per_image:.2f}ç§’/å¼ ",
            "",
            "## ğŸ’¾ ç³»ç»Ÿèµ„æº",
            f"**å†…å­˜ä½¿ç”¨**: {self.memory_after['rss_mb']:.1f}MB",
            f"**ç³»ç»Ÿå†…å­˜**: {self.memory_after['percent']:.1f}%",
        ]

        if self.gpu_after:
            report_lines.extend([
                f"**GPUåˆ©ç”¨ç‡**: {self.gpu_after['load']:.1f}%",
                f"**GPUæ˜¾å­˜**: {self.gpu_after['memory_used']}/{self.gpu_after['memory_total']}MB ({self.gpu_after['memory_percent']:.1f}%)",
            ])

        if self.gpu_before and self.gpu_after:
            gpu_memory_increase = self.gpu_after['memory_used'] - self.gpu_before['memory_used']
            report_lines.append(f"**æ˜¾å­˜å¢é‡**: {gpu_memory_increase:.1f}MB")

        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        if current_model_type:
            report_lines.append("")
            report_lines.append("## ğŸ¤– æ¨¡å‹ä¿¡æ¯")
            report_lines.append(f"**å½“å‰æ¨¡å‹**: {current_model_type}")
            if current_adapter_path:
                report_lines.append(f"**é€‚é…å™¨è·¯å¾„**: {current_adapter_path}")

        return "\n".join(report_lines)


def check_finetuned_model_exists(adapter_path: str) -> bool:
    """æ£€æŸ¥å¾®è°ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨"""
    if os.path.exists(adapter_path):
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["adapter_config.json", "adapter_model.safetensors"]
        model_files = os.listdir(adapter_path)
        has_required = any(file in model_files for file in required_files)

        if has_required:
            print(f"âœ… å¾®è°ƒæ¨¡å‹å­˜åœ¨ä¸”å®Œæ•´: {adapter_path}")
            return True
        else:
            print(f"âš ï¸ å¾®è°ƒæ¨¡å‹ç›®å½•å­˜åœ¨ä½†ç¼ºå°‘å¿…è¦æ–‡ä»¶: {adapter_path}")
            return False
    else:
        print(f"âŒ å¾®è°ƒæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {adapter_path}")
        return False


def load_model_and_tokenizer(model_type: str, adapter_path: str = None) -> None:
    """
    åŠ è½½æŒ‡å®šçš„æ¨¡å‹å’Œåˆ†è¯å™¨

    Args:
        model_type: æ¨¡å‹ç±»å‹
        adapter_path: LoRAé€‚é…å™¨è·¯å¾„ï¼ˆå¯¹äºå¾®è°ƒæ¨¡å‹ï¼‰
    """
    global model, tokenizer, current_model_type, current_adapter_path

    # å¦‚æœæ¨¡å‹ç±»å‹å’Œé€‚é…å™¨è·¯å¾„æ²¡æœ‰å˜åŒ–ï¼Œåˆ™ä¸éœ€è¦é‡æ–°åŠ è½½
    if (model_type == current_model_type and
            (not MODEL_CONFIGS[model_type]["is_custom"] or adapter_path == current_adapter_path)):
        print("âœ… æ¨¡å‹å·²åŠ è½½ï¼Œæ— éœ€é‡æ–°åŠ è½½")
        return

    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_type}")

    try:
        # æ¸…é™¤ä¹‹å‰çš„æ¨¡å‹ä»¥é‡Šæ”¾å†…å­˜
        if model is not None:
            del model
            torch.cuda.empty_cache()

        model_config = MODEL_CONFIGS[model_type]
        model_name = model_config["model_name"]

        if model_config["is_custom"]:
            # ä½¿ç”¨æä¾›çš„é€‚é…å™¨è·¯å¾„æˆ–é»˜è®¤è·¯å¾„
            actual_adapter_path = adapter_path if adapter_path else model_config.get("adapter_path", "./final_model")

            # æ£€æŸ¥å¾®è°ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨
            if not check_finetuned_model_exists(actual_adapter_path):
                raise gr.Error(f"å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨æˆ–æ–‡ä»¶ä¸å®Œæ•´ï¼è·¯å¾„: {actual_adapter_path}")

            print(f"ğŸ“ åŠ è½½å¾®è°ƒæ¨¡å‹ï¼Œé€‚é…å™¨è·¯å¾„: {actual_adapter_path}")
        else:
            print(f"ğŸŒ åŠ è½½åŸå§‹æ¨¡å‹: {model_name}")

        # åŠ è½½tokenizer
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

        # åŠ è½½åŸºç¡€æ¨¡å‹
        base_model = AutoModel.from_pretrained(
            model_name,
            attn_implementation="eager",
            trust_remote_code=True,
            use_safetensors=True,
            device_map="auto",
            torch_dtype=torch.float16,
        )

        # å¦‚æœæ˜¯å¾®è°ƒæ¨¡å‹ï¼ŒåŠ è½½LoRAé€‚é…å™¨
        if model_config["is_custom"]:
            model = PeftModel.from_pretrained(
                base_model,
                actual_adapter_path,
                torch_dtype=torch.float16
            )
            current_adapter_path = actual_adapter_path
        else:
            model = base_model
            current_adapter_path = None

        model = model.eval()

        # æ›´æ–°å½“å‰æ¨¡å‹ä¿¡æ¯
        current_model_type = model_type

        print(f"âœ… {model_type} åŠ è½½æˆåŠŸ")

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("å°è¯•å¤‡é€‰åŠ è½½æ–¹å¼...")

        try:
            base_model = AutoModel.from_pretrained(
                model_name,
                trust_remote_code=True,
                use_safetensors=True,
                device_map="auto"
            )

            if model_config["is_custom"] and actual_adapter_path:
                model = PeftModel.from_pretrained(
                    base_model,
                    actual_adapter_path
                )
                current_adapter_path = actual_adapter_path
            else:
                model = base_model
                current_adapter_path = None

            model = model.eval()

            current_model_type = model_type

            print(f"âœ… {model_type} é€šè¿‡å¤‡é€‰æ–¹å¼åŠ è½½æˆåŠŸ")
        except Exception as e2:
            print(f"âŒ å¤‡é€‰åŠ è½½æ–¹å¼ä¹Ÿå¤±è´¥: {e2}")
            raise gr.Error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e2}")


def move_model_to_gpu() -> None:
    """å¦‚æœæ¨¡å‹å°šæœªåœ¨GPUä¸Šï¼Œåˆ™å°†å…¶ç§»åŠ¨åˆ°GPU"""
    global model_gpu
    if model_gpu is None and model is not None:
        print("ğŸš€ æ­£åœ¨å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU...")
        model_gpu = model.cuda().to(torch.bfloat16, non_blocking=True)
        print("âœ… æ¨¡å‹å·²åœ¨GPUä¸Š")


def find_result_image(path: str) -> Optional[Image.Image]:
    """åœ¨æŒ‡å®šè·¯å¾„ä¸­æŸ¥æ‰¾é¢„ç”Ÿæˆçš„ç»“æœå›¾åƒ"""
    for filename in os.listdir(path):
        if "grounding" in filename or "result" in filename:
            try:
                image_path = os.path.join(path, filename)
                return Image.open(image_path)
            except Exception as e:
                print(f"æ‰“å¼€ç»“æœå›¾åƒ {filename} æ—¶å‡ºé”™: {e}")
    return None


def build_prompt(task_type: str, ref_text: str) -> str:
    """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå‚è€ƒæ–‡æœ¬æ„å»ºé€‚å½“çš„æç¤º"""
    if task_type == "ğŸ¯ é€šè¿‡å‚è€ƒå®šä½å¯¹è±¡":
        if not ref_text or ref_text.strip() == "":
            raise gr.Error("å¯¹äº'å®šä½'ä»»åŠ¡ï¼Œæ‚¨å¿…é¡»æä¾›è¦æŸ¥æ‰¾çš„å‚è€ƒæ–‡æœ¬ï¼")
        return f"<image>\nåœ¨å›¾åƒä¸­å®šä½ <|ref|>{ref_text.strip()}<|/ref|>."

    return TASK_PROMPTS.get(task_type, TASK_PROMPTS["ğŸ“ è‡ªç”±OCR"])


def extract_and_draw_bounding_boxes(text_result: str, original_image: Image.Image) -> Optional[Image.Image]:
    """ä»æ–‡æœ¬ç»“æœä¸­æå–è¾¹ç•Œæ¡†åæ ‡å¹¶åœ¨å›¾åƒä¸Šç»˜åˆ¶å®ƒä»¬"""
    matches = list(BOUNDING_BOX_PATTERN.finditer(text_result))

    if not matches:
        return None

    print(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªè¾¹ç•Œæ¡†ã€‚æ­£åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶ã€‚")

    image_with_bboxes = original_image.copy()
    draw = ImageDraw.Draw(image_with_bboxes)
    w, h = original_image.size

    w_scale = w / NORMALIZATION_FACTOR
    h_scale = h / NORMALIZATION_FACTOR

    for match in matches:
        coords = tuple(int(c) for c in match.groups())
        x1_norm, y1_norm, x2_norm, y2_norm = coords

        x1 = int(x1_norm * w_scale)
        y1 = int(y1_norm * h_scale)
        x2 = int(x2_norm * w_scale)
        y2 = int(y2_norm * h_scale)

        draw.rectangle([x1, y1, x2, y2], outline=BOUNDING_BOX_COLOR, width=BOUNDING_BOX_WIDTH)

    return image_with_bboxes


def run_inference(prompt: str, image_path: str, output_path: str, config: Dict[str, Any]) -> Tuple[str, float]:
    """ä½¿ç”¨ç»™å®šå‚æ•°è¿è¡Œæ¨¡å‹æ¨ç†"""
    print(f"ğŸƒ ä½¿ç”¨æç¤ºè¿è¡Œæ¨ç†: {prompt}")

    inference_start = time.time()

    text_result = model_gpu.infer(
        tokenizer,
        prompt=prompt,
        image_file=image_path,
        output_path=output_path,
        base_size=config["base_size"],
        image_size=config["image_size"],
        crop_mode=config["crop_mode"],
        save_results=True,
        test_compress=True,
        eval_mode=True,
    )

    inference_time = time.time() - inference_start

    print(f"====\nğŸ“„ æ–‡æœ¬ç»“æœ: {text_result}\nâ±ï¸ æ¨ç†æ—¶é—´: {inference_time:.2f}ç§’\n====")
    return text_result, inference_time


def pdf_to_images(pdf_file: str, dpi: int = 200) -> list:
    """å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºå›¾åƒåˆ—è¡¨"""
    images = []
    try:
        pdf_document = fitz.open(pdf_file)

        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]
            pix = page.get_pixmap(matrix=fitz.Matrix(dpi / 72, dpi / 72))
            img_data = pix.tobytes("ppm")
            img = Image.open(io.BytesIO(img_data))

            if img.mode != 'RGB':
                img = img.convert('RGB')

            images.append(img)

        pdf_document.close()
        print(f"âœ… PDFè½¬æ¢æˆåŠŸï¼Œå…± {len(images)} é¡µ")

    except Exception as e:
        print(f"âŒ PDFè½¬æ¢å¤±è´¥: {e}")
        raise gr.Error(f"PDFè½¬æ¢å¤±è´¥: {str(e)}")

    return images


def process_pdf_ocr(pdf_file: str, model_size: str, task_type: str, ref_text: str,
                    model_type: str, adapter_path: str) -> Tuple[str, str, List[Tuple[Image.Image, str]]]:
    """å¤„ç†PDFæ–‡ä»¶çš„OCRä»»åŠ¡"""
    # å…ˆåŠ è½½æ¨¡å‹
    load_model_and_tokenizer(model_type, adapter_path)
    move_model_to_gpu()

    prompt = build_prompt(task_type, ref_text)
    config = MODEL_SIZE_CONFIGS.get(model_size, MODEL_SIZE_CONFIGS[DEFAULT_MODEL_SIZE])

    pdf_images = pdf_to_images(pdf_file)

    if not pdf_images:
        return "PDFè½¬æ¢å¤±è´¥æˆ–ä¸ºç©ºPDFæ–‡ä»¶ã€‚", "", []

    performance_monitor = PerformanceMonitor()
    performance_monitor.start()

    all_results = []
    all_result_images = []
    total_inference_time = 0

    with tempfile.TemporaryDirectory() as output_path:
        for i, page_image in enumerate(pdf_images):
            temp_image_path = os.path.join(output_path, f"temp_page_{i + 1}.png")
            page_image.save(temp_image_path, optimize=True)

            text_result, inference_time = run_inference(prompt, temp_image_path, output_path, config)
            total_inference_time += inference_time

            page_result = f"--- ç¬¬ {i + 1} é¡µ ---\n{text_result}\n"
            all_results.append(page_result)

            result_image = extract_and_draw_bounding_boxes(text_result, page_image)

            if result_image is None:
                print(f"âš ï¸ åœ¨ç¬¬ {i + 1} é¡µæ–‡æœ¬ç»“æœä¸­æœªæ‰¾åˆ°è¾¹ç•Œæ¡†åæ ‡ã€‚å›é€€åˆ°æœç´¢ç»“æœå›¾åƒæ–‡ä»¶ã€‚")
                found_image = find_result_image(output_path)
                if found_image:
                    result_image = found_image
                else:
                    result_image = page_image.copy()

            label = f"ç¬¬ {i + 1} é¡µ"
            all_result_images.append((result_image, label))

    performance_monitor.stop()
    final_text = "\n".join(all_results)
    performance_report = performance_monitor.get_performance_report(len(pdf_images))

    return performance_report, final_text, all_result_images


def process_image_ocr(image: Image.Image, model_size: str, task_type: str, ref_text: str,
                      model_type: str, adapter_path: str) -> Tuple[str, str, List[Tuple[Image.Image, str]]]:
    """å¤„ç†å•å¼ å›¾åƒçš„OCRä»»åŠ¡"""
    # å…ˆåŠ è½½æ¨¡å‹
    load_model_and_tokenizer(model_type, adapter_path)
    move_model_to_gpu()

    prompt = build_prompt(task_type, ref_text)
    config = MODEL_SIZE_CONFIGS.get(model_size, MODEL_SIZE_CONFIGS[DEFAULT_MODEL_SIZE])

    performance_monitor = PerformanceMonitor()
    performance_monitor.start()

    with tempfile.TemporaryDirectory() as output_path:
        temp_image_path = os.path.join(output_path, "temp_image.png")
        image.save(temp_image_path, optimize=True)

        text_result, inference_time = run_inference(prompt, temp_image_path, output_path, config)
        performance_monitor.stop()

        result_image = extract_and_draw_bounding_boxes(text_result, image)

        if result_image is None:
            print("âš ï¸ åœ¨æ–‡æœ¬ç»“æœä¸­æœªæ‰¾åˆ°è¾¹ç•Œæ¡†åæ ‡ã€‚å›é€€åˆ°æœç´¢ç»“æœå›¾åƒæ–‡ä»¶ã€‚")
            found_image = find_result_image(output_path)
            if found_image:
                result_image = found_image
            else:
                result_image = image.copy()

        result_images = [(result_image, "å¤„ç†ç»“æœ")]
        performance_report = performance_monitor.get_performance_report(1)

        return performance_report, text_result, result_images


def process_ocr_task(file_input: Any, model_size: str, task_type: str, ref_text: str,
                     model_type: str, adapter_path: str) -> Tuple[str, str, List[Tuple[Image.Image, str]]]:
    """ä½¿ç”¨DeepSeek-OCRå¤„ç†å›¾åƒæˆ–PDFä»¥æ”¯æŒæ‰€æœ‰ä»»åŠ¡"""
    if file_input is None:
        return "è¯·å…ˆä¸Šä¼ å›¾åƒæˆ–PDFæ–‡ä»¶ã€‚", "", []

    try:
        if isinstance(file_input, str) and file_input.lower().endswith('.pdf'):
            return process_pdf_ocr(file_input, model_size, task_type, ref_text, model_type, adapter_path)
        else:
            image = file_input if not isinstance(file_input, str) else Image.open(file_input)
            return process_image_ocr(image, model_size, task_type, ref_text, model_type, adapter_path)
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f"âŒ {error_msg}")
        return error_msg, "", []


def toggle_ref_text_visibility(task: str) -> gr.Textbox:
    """æ ¹æ®ä»»åŠ¡ç±»å‹åˆ‡æ¢å‚è€ƒæ–‡æœ¬è¾“å…¥çš„å¯è§æ€§"""
    return gr.Textbox(visible=True) if task == "ğŸ¯ é€šè¿‡å‚è€ƒå®šä½å¯¹è±¡" else gr.Textbox(visible=False)


def toggle_adapter_path_visibility(model_type: str) -> gr.Textbox:
    """æ ¹æ®æ¨¡å‹ç±»å‹åˆ‡æ¢é€‚é…å™¨è·¯å¾„è¾“å…¥çš„å¯è§æ€§"""
    return gr.Textbox(visible=True) if model_type == "ğŸ¯ å¾®è°ƒæ¨¡å‹ (LoRA)" else gr.Textbox(visible=False)


def get_model_status(model_type: str, adapter_path: str) -> str:
    """è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯"""
    if model_type == "ğŸ¯ å¾®è°ƒæ¨¡å‹ (LoRA)":
        actual_path = adapter_path if adapter_path else MODEL_CONFIGS[model_type]["adapter_path"]
        if check_finetuned_model_exists(actual_path):
            return f"âœ… å¾®è°ƒæ¨¡å‹å·²å°±ç»ª: {actual_path}"
        else:
            return f"âŒ å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨æˆ–æ–‡ä»¶ä¸å®Œæ•´: {actual_path}"
    else:
        return "âœ… åŸå§‹æ¨¡å‹å·²å°±ç»ª"


# é«˜çº§CSSæ ·å¼ - ç°ä»£åŒ–è®¾è®¡
custom_css = """
/* åŸºç¡€é‡ç½®å’Œå˜é‡ */
:root {
    --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    --secondary-gradient: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    --accent-gradient: linear-gradient(45deg, #4facfe 0%, #00f2fe 100%);
    --success-gradient: linear-gradient(45deg, #43e97b 0%, #38f9d7 100%);
    --warning-gradient: linear-gradient(45deg, #fa709a 0%, #fee140 100%);
    --dark-bg: #1a1a2e;
    --darker-bg: #16213e;
    --card-bg: rgba(255, 255, 255, 0.1);
    --text-light: #ffffff;
    --text-muted: rgba(255, 255, 255, 0.8);
    --shadow-soft: 0 8px 32px rgba(0, 0, 0, 0.1);
    --shadow-hard: 0 20px 40px rgba(0, 0, 0, 0.2);
}

/* ä¸»å®¹å™¨æ ·å¼ */
.gradio-container {
    background: var(--primary-gradient) !important;
    min-height: 100vh;
    font-family: 'Segoe UI', system-ui, -apple-system, sans-serif !important;
}

/* æ ‡é¢˜åŒºåŸŸ */
.title-section {
    background: linear-gradient(135deg, rgba(102, 126, 234, 0.9) 0%, rgba(118, 75, 162, 0.9) 100%) !important;
    backdrop-filter: blur(20px);
    border-radius: 0 0 40px 40px !important;
    padding: 40px 20px !important;
    margin-bottom: 30px !important;
    box-shadow: var(--shadow-hard);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.main-title {
    text-align: center;
    font-weight: 800;
    background: linear-gradient(45deg, #FFD93D, #6BCF7F, #4D96FF);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 3em !important;
    margin-bottom: 15px !important;
    text-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
}

.subtitle {
    font-size: 1.4em !important;
    color: var(--text-light) !important;
    opacity: 0.9;
    margin-bottom: 25px !important;
    font-weight: 300;
}

/* å¡ç‰‡å’Œå®¹å™¨ */
.gr-box, .gradio-group {
    background: rgba(255, 255, 255, 0.95) !important;
    backdrop-filter: blur(20px);
    border-radius: 24px !important;
    border: 1px solid rgba(255, 255, 255, 0.3) !important;
    box-shadow: var(--shadow-soft) !important;
    margin: 12px !important;
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
}

.gr-box:hover, .gradio-group:hover {
    transform: translateY(-5px);
    box-shadow: var(--shadow-hard) !important;
}

/* æŒ‰é’®æ ·å¼ */
button {
    border-radius: 16px !important;
    background: var(--accent-gradient) !important;
    border: none !important;
    color: white !important;
    font-weight: 600 !important;
    padding: 16px 32px !important;
    margin: 8px !important;
    transition: all 0.3s ease !important;
    position: relative;
    overflow: hidden;
    box-shadow: 0 8px 25px rgba(77, 150, 255, 0.3);
}

button:hover {
    transform: translateY(-3px) scale(1.02);
    box-shadow: 0 12px 35px rgba(77, 150, 255, 0.4);
}

button:active {
    transform: translateY(0) scale(0.98);
}

button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
    transition: left 0.5s;
}

button:hover::before {
    left: 100%;
}

/* è¾“å…¥æ¡†å’Œä¸‹æ‹‰èœå• */
input, textarea, select, .gr-dropdown {
    border-radius: 16px !important;
    border: 2px solid rgba(77, 150, 255, 0.2) !important;
    background: rgba(248, 250, 252, 0.8) !important;
    padding: 16px 20px !important;
    transition: all 0.3s ease !important;
    font-size: 14px !important;
}

input:focus, textarea:focus, select:focus, .gr-dropdown:focus {
    border-color: #4D96FF !important;
    box-shadow: 0 0 0 4px rgba(77, 150, 255, 0.1) !important;
    background: white !important;
    transform: translateY(-2px);
}

/* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
.upload-area {
    border: 3px dashed #4D96FF !important;
    border-radius: 24px !important;
    background: rgba(77, 150, 255, 0.05) !important;
    transition: all 0.3s ease !important;
    padding: 50px 30px !important;
    text-align: center;
    position: relative;
    overflow: hidden;
}

.upload-area::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: var(--accent-gradient);
    opacity: 0;
    transition: opacity 0.3s ease;
}

.upload-area:hover {
    border-color: #FF6B6B !important;
    background: rgba(255, 107, 107, 0.05) !important;
    transform: scale(1.02);
}

.upload-area:hover::before {
    opacity: 0.1;
}

/* é€‰é¡¹å¡æ ·å¼ */
.gr-tabs {
    border-radius: 24px !important;
    background: white !important;
    box-shadow: var(--shadow-soft) !important;
}

.tab-nav {
    background: var(--accent-gradient) !important;
    border-radius: 20px 20px 0 0 !important;
    padding: 10px !important;
}

.tab-nav .tab-button {
    border-radius: 12px !important;
    margin: 0 5px !important;
    transition: all 0.3s ease !important;
}

.tab-nav .tab-button.selected {
    background: rgba(255, 255, 255, 0.2) !important;
    backdrop-filter: blur(10px);
}

/* ç”»å»Šæ ·å¼ */
.gallery {
    border-radius: 24px !important;
    background: white !important;
    padding: 25px !important;
    box-shadow: var(--shadow-soft);
}

.gallery .thumbnail {
    border-radius: 16px !important;
    transition: all 0.3s ease !important;
}

.gallery .thumbnail:hover {
    transform: scale(1.05);
    box-shadow: var(--shadow-hard);
}

/* æ€§èƒ½å¡ç‰‡ */
.performance-card {
    background: var(--success-gradient) !important;
    border-radius: 20px !important;
    padding: 25px !important;
    color: white !important;
    box-shadow: var(--shadow-soft);
}

/* æ ‡ç­¾å’Œæ–‡æœ¬ */
.label {
    font-weight: 700 !important;
    color: #2d3748 !important;
    margin-bottom: 12px !important;
    font-size: 1.1em !important;
    display: flex;
    align-items: center;
    gap: 8px;
}

/* å¾½ç« æ ·å¼ */
.badge-container {
    display: flex;
    justify-content: center;
    gap: 12px;
    flex-wrap: wrap;
    margin: 20px 0;
}

.badge {
    background: rgba(255, 255, 255, 0.2);
    padding: 10px 20px;
    border-radius: 20px;
    color: white;
    font-size: 0.9em;
    font-weight: 500;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.3);
    transition: all 0.3s ease;
}

.badge:hover {
    background: rgba(255, 255, 255, 0.3);
    transform: translateY(-2px);
}

/* åŠ è½½åŠ¨ç”» */
@keyframes shimmer {
    0% { transform: translateX(-100%); }
    100% { transform: translateX(100%); }
}

.loading-shimmer {
    position: relative;
    overflow: hidden;
}

.loading-shimmer::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: linear-gradient(90deg, transparent, rgba(255,255,255,0.4), transparent);
    animation: shimmer 1.5s infinite;
}

/* çŠ¶æ€æŒ‡ç¤ºå™¨ */
.status-indicator {
    width: 12px;
    height: 12px;
    border-radius: 50%;
    display: inline-block;
    margin-right: 8px;
    box-shadow: 0 0 10px currentColor;
}

.status-ready {
    background: #6BCF7F;
    animation: pulse-green 2s infinite;
}

.status-processing {
    background: #FFD93D;
    animation: pulse-yellow 1.5s infinite;
}

@keyframes pulse-green {
    0%, 100% { 
        box-shadow: 0 0 0 0 rgba(107, 207, 127, 0.7);
    }
    70% { 
        box-shadow: 0 0 0 10px rgba(107, 207, 127, 0);
    }
}

@keyframes pulse-yellow {
    0%, 100% { 
        box-shadow: 0 0 0 0 rgba(255, 217, 61, 0.7);
    }
    70% { 
        box-shadow: 0 0 0 10px rgba(255, 217, 61, 0);
    }
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
    .main-title {
        font-size: 2.2em !important;
    }

    .subtitle {
        font-size: 1.1em !important;
    }

    .gr-box {
        margin: 8px !important;
        border-radius: 20px !important;
    }

    .badge-container {
        gap: 8px;
    }

    .badge {
        padding: 8px 16px;
        font-size: 0.8em;
    }
}

/* æ»šåŠ¨æ¡ç¾åŒ– */
::-webkit-scrollbar {
    width: 8px;
}

::-webkit-scrollbar-track {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 10px;
}

::-webkit-scrollbar-thumb {
    background: var(--accent-gradient);
    border-radius: 10px;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--secondary-gradient);
}

/* å›¾æ ‡åŠ¨ç”» */
.icon-animation {
    animation: float 3s ease-in-out infinite;
}

@keyframes float {
    0%, 100% { 
        transform: translateY(0px) rotate(0deg); 
    }
    50% { 
        transform: translateY(-10px) rotate(5deg); 
    }
}

/* ç½‘æ ¼èƒŒæ™¯ */
.grid-bg {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: 
        linear-gradient(rgba(255,255,255,0.1) 1px, transparent 1px),
        linear-gradient(90deg, rgba(255,255,255,0.1) 1px, transparent 1px);
    background-size: 50px 50px;
    pointer-events: none;
    z-index: -1;
}
"""


def create_ui() -> gr.Blocks:
    """åˆ›å»ºå’Œé…ç½®Gradioç”¨æˆ·ç•Œé¢"""
    with gr.Blocks(
            title="ğŸš€ DeepSeek-OCR æ™ºèƒ½æ–‡æ¡£è¯†åˆ«ç³»ç»Ÿ",
            theme=gr.themes.Soft(
                primary_hue="blue",
                secondary_hue="pink",
                neutral_hue="slate",
                font=[gr.themes.GoogleFont("Inter"), "Segoe UI", "system-ui", "sans-serif"]
            ),
            css=custom_css
    ) as demo:
        # ç½‘æ ¼èƒŒæ™¯
        gr.HTML("""
        <div class="grid-bg"></div>
        """)

        # ä¸»æ ‡é¢˜å’Œæè¿°
        gr.HTML("""
        <div class="title-section">
            <h1 class="main-title">ğŸš€ DeepSeek-OCR æ™ºèƒ½æ–‡æ¡£è¯†åˆ«ç³»ç»Ÿ</h1>
            <p class="subtitle">æ”¯æŒåŸå§‹æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹çš„åŒé‡OCRè§£å†³æ–¹æ¡ˆ</p>
            <div class="badge-container">
                <span class="badge">ğŸ“„ PDFå¤šé¡µå¤„ç†</span>
                <span class="badge">ğŸ¯ åŒæ¨¡å‹æ”¯æŒ</span>
                <span class="badge">ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§</span>
                <span class="badge">ğŸ–¼ï¸ å¯è§†åŒ–æ ‡æ³¨</span>
                <span class="badge">âš¡ æé€Ÿæ¨ç†</span>
                <span class="badge">ğŸ”§ LoRAå¾®è°ƒ</span>
            </div>
        </div>
        """)

        with gr.Row(equal_height=False, variant="panel"):
            # å·¦ä¾§é…ç½®é¢æ¿
            with gr.Column(scale=1, min_width=420, variant="compact"):
                with gr.Group():
                    gr.Markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ")
                    file_input = gr.File(
                        label="ğŸ–¼ï¸ æ‹–æ”¾æˆ–é€‰æ‹©å›¾åƒ/PDFæ–‡ä»¶",
                        file_types=[".png", ".jpg", ".jpeg", ".gif", ".bmp", ".pdf"],
                        type="filepath",
                        elem_classes="upload-area",
                        height=220,
                        scale=1
                    )

                with gr.Group():
                    gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©é…ç½®")

                    with gr.Row():
                        model_type = gr.Dropdown(
                            choices=list(MODEL_CONFIGS.keys()),
                            value=DEFAULT_MODEL_TYPE,
                            label="ğŸ”§ é€‰æ‹©æ¨¡å‹ç±»å‹",
                            info="é€‰æ‹©ä½¿ç”¨åŸå§‹æ¨¡å‹æˆ–å¾®è°ƒæ¨¡å‹",
                            scale=2
                        )

                    adapter_path_input = gr.Textbox(
                        label="ğŸ“ å¾®è°ƒæ¨¡å‹è·¯å¾„ (LoRAé€‚é…å™¨)",
                        placeholder="è¯·è¾“å…¥å¾®è°ƒæ¨¡å‹çš„è·¯å¾„ï¼Œä¾‹å¦‚: ./final_model",
                        value="./final_model",
                        visible=False,
                        lines=2,
                        info="å½“é€‰æ‹©'å¾®è°ƒæ¨¡å‹'æ—¶éœ€è¦æä¾›LoRAé€‚é…å™¨è·¯å¾„"
                    )

                    # æ¨¡å‹çŠ¶æ€æ˜¾ç¤º
                    model_status = gr.Markdown(get_model_status(DEFAULT_MODEL_TYPE, "./final_model"))

                    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€æŒ‰é’®
                    check_model_btn = gr.Button("ğŸ”„ æ£€æŸ¥æ¨¡å‹çŠ¶æ€", variant="secondary", size="sm")

                with gr.Group():
                    gr.Markdown("### âš™ï¸ å¤„ç†å‚æ•°è®¾ç½®")

                    with gr.Row():
                        model_size = gr.Dropdown(
                            choices=list(MODEL_SIZE_CONFIGS.keys()),
                            value=DEFAULT_MODEL_SIZE,
                            label="ğŸ”§ è¯†åˆ«æ¨¡å¼é€‰æ‹©",
                            info="æ ¹æ®æ–‡æ¡£ç±»å‹å’Œéœ€æ±‚é€‰æ‹©åˆé€‚çš„å¤„ç†æ¨¡å¼",
                            scale=2
                        )

                    with gr.Row():
                        task_type = gr.Dropdown(
                            choices=list(TASK_PROMPTS.keys()) + ["ğŸ¯ é€šè¿‡å‚è€ƒå®šä½å¯¹è±¡"],
                            value=DEFAULT_TASK_TYPE,
                            label="ğŸ¯ ä»»åŠ¡ç±»å‹é€‰æ‹©",
                            info="é€‰æ‹©é€‚åˆæ‚¨éœ€æ±‚çš„OCRä»»åŠ¡ç±»å‹",
                            scale=2
                        )

                    ref_text_input = gr.Textbox(
                        label="ğŸ” å‚è€ƒæ–‡æœ¬è¾“å…¥ï¼ˆå®šä½ä»»åŠ¡ä¸“ç”¨ï¼‰",
                        placeholder="è¯·è¾“å…¥æ‚¨è¦å®šä½çš„æ–‡æœ¬å†…å®¹ï¼Œä¾‹å¦‚ï¼šæ ‡é¢˜ã€å…³é”®è¯ã€ç‰¹å®šå¯¹è±¡...",
                        visible=False,
                        lines=3,
                        max_lines=4
                    )

                with gr.Group():
                    gr.Markdown("### ğŸ¯ æ“ä½œæ§åˆ¶é¢æ¿")
                    with gr.Row():
                        submit_btn = gr.Button("ğŸš€ å¼€å§‹æ™ºèƒ½è¯†åˆ«", variant="primary", size="lg", scale=2)
                        clear_btn = gr.Button("ğŸ§¹ ä¸€é”®æ¸…ç©º", variant="secondary", scale=1)

                    gr.Markdown("""
                    **ğŸ’¡ ä½¿ç”¨æç¤ºï¼š**
                    - æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼å’ŒPDFæ–‡æ¡£
                    - å¤§æ–‡ä»¶å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
                    - å®šä½ä»»åŠ¡éœ€è¦æä¾›å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬
                    - å¾®è°ƒæ¨¡å‹éœ€è¦LoRAé€‚é…å™¨æ–‡ä»¶
                    - åˆ‡æ¢æ¨¡å‹ç±»å‹åé¦–æ¬¡åŠ è½½éœ€è¦æ—¶é—´
                    """)

            # å³ä¾§ç»“æœé¢æ¿
            with gr.Column(scale=2, min_width=800, variant="panel"):
                with gr.Tabs(selected=0) as tabs:
                    with gr.TabItem("ğŸ“Š æ€§èƒ½åˆ†æé¢æ¿", id=0):
                        performance_output = gr.Markdown(
                            value="""
                            **ç³»ç»ŸçŠ¶æ€**: <span class='status-indicator status-ready'></span> å°±ç»ªç­‰å¾…ä¸­

                            ### ğŸ¯ å°±ç»ªçŠ¶æ€
                            - ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ
                            - ç­‰å¾…æ¨¡å‹é€‰æ‹©å’Œæ–‡ä»¶ä¸Šä¼ 
                            - æ”¯æŒåŸå§‹æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹

                            ### ğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œ
                            è¯·é€‰æ‹©æ¨¡å‹ç±»å‹å¹¶ä¸Šä¼ å›¾åƒæˆ–PDFæ–‡ä»¶ï¼Œç„¶åç‚¹å‡»"å¼€å§‹æ™ºèƒ½è¯†åˆ«"æŒ‰é’®
                            """,
                            elem_classes="performance-card"
                        )

                    with gr.TabItem("ğŸ“„ æ–‡æœ¬è¯†åˆ«ç»“æœ", id=1):
                        with gr.Group():
                            output_text = gr.Textbox(
                                label="ğŸ“ è¯†åˆ«æ–‡æœ¬è¾“å‡º",
                                lines=20,
                                show_copy_button=True,
                                placeholder="è¯†åˆ«ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...\n\nâœ¨ åŠŸèƒ½ç‰¹è‰²ï¼š\nâ€¢ æ”¯æŒMarkdownæ ¼å¼è¾“å‡º\nâ€¢ ä¸€é”®å¤åˆ¶ç»“æœ\nâ€¢ æ™ºèƒ½æ–‡æœ¬æ ¼å¼åŒ–\nâ€¢ å¤šè¯­è¨€è¯†åˆ«æ”¯æŒ",
                                elem_id="result-text",
                                max_lines=25
                            )

                    with gr.TabItem("ğŸ–¼ï¸ å¯è§†åŒ–ç»“æœ", id=2):
                        with gr.Group():
                            output_gallery = gr.Gallery(
                                label="ğŸ–¼ï¸ æ ‡æ³¨ç»“æœé¢„è§ˆ",
                                show_label=True,
                                elem_id="result-gallery",
                                columns=3,
                                rows=2,
                                height="auto",
                                object_fit="contain",
                                preview=True,
                                show_download_button=True
                            )

        # åº•éƒ¨ä¿¡æ¯æ 
        gr.HTML("""
        <div style="
            text-align: center; 
            margin-top: 50px; 
            padding: 40px 30px; 
            background: linear-gradient(135deg, rgba(44, 62, 80, 0.9) 0%, rgba(52, 152, 219, 0.9) 100%);
            border-radius: 30px; 
            color: white;
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 20px 40px rgba(0,0,0,0.2);
        ">
            <h3 style="margin-bottom: 30px; font-size: 2em; background: linear-gradient(45deg, #FFD93D, #6BCF7F); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">âœ¨ åŒæ¨¡å‹æ”¯æŒç‰¹æ€§</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 30px; text-align: left; margin-bottom: 40px;">
                <div style="background: rgba(255,255,255,0.1); padding: 25px; border-radius: 20px; backdrop-filter: blur(10px);">
                    <h4 style="color: #4D96FF; margin-bottom: 15px; font-size: 1.3em;">ğŸ¤– åŸå§‹æ¨¡å‹</h4>
                    <p style="line-height: 1.6; opacity: 0.9;">ä½¿ç”¨å®˜æ–¹DeepSeek-OCRæ¨¡å‹ï¼Œæä¾›ç¨³å®šå¯é çš„OCRè¯†åˆ«èƒ½åŠ›ï¼Œé€‚åˆé€šç”¨åœºæ™¯</p>
                </div>
                <div style="background: rgba(255,255,255,0.1); padding: 25px; border-radius: 20px; backdrop-filter: blur(10px);">
                    <h4 style="color: #6BCF7F; margin-bottom: 15px; font-size: 1.3em;">ğŸ¯ å¾®è°ƒæ¨¡å‹</h4>
                    <p style="line-height: 1.6; opacity: 0.9;">åŸºäºLoRAæŠ€æœ¯çš„å¾®è°ƒæ¨¡å‹ï¼Œé’ˆå¯¹ç‰¹å®šé¢†åŸŸä¼˜åŒ–ï¼Œæä¾›æ›´ç²¾å‡†çš„è¯†åˆ«æ•ˆæœ</p>
                </div>
                <div style="background: rgba(255,255,255,0.1); padding: 25px; border-radius: 20px; backdrop-filter: blur(10px);">
                    <h4 style="color: #FFD93D; margin-bottom: 15px; font-size: 1.3em;">ğŸ”„ çµæ´»åˆ‡æ¢</h4>
                    <p style="line-height: 1.6; opacity: 0.9;">æ”¯æŒåœ¨åŸå§‹æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹ä¹‹é—´æ— ç¼åˆ‡æ¢ï¼Œæ— éœ€é‡å¯åº”ç”¨</p>
                </div>
                <div style="background: rgba(255,255,255,0.1); padding: 25px; border-radius: 20px; backdrop-filter: blur(10px);">
                    <h4 style="color: #FF6B6B; margin-bottom: 15px; font-size: 1.3em;">ğŸ“Š æ€§èƒ½ç›‘æ§</h4>
                    <p style="line-height: 1.6; opacity: 0.9;">å®æ—¶ç›‘æ§ä¸¤ç§æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ï¼Œæä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œèµ„æºä½¿ç”¨æƒ…å†µ</p>
                </div>
            </div>
            <div style="
                margin-top: 30px; 
                border-top: 1px solid rgba(255,255,255,0.3); 
                padding-top: 25px;
                display: flex;
                justify-content: space-between;
                align-items: center;
                flex-wrap: wrap;
                gap: 20px;
            ">
                <div style="text-align: left;">
                    <p style="margin-bottom: 8px; font-size: 1.1em;"><strong>ğŸ‘¥ æ ¸å¿ƒå¼€å‘å›¢é˜Ÿ</strong></p>
                    <p style="opacity: 0.9;">æ¢å±•è±ª Â· å‘¨å­ç¥– Â· æ½˜ç¥¥ç‘œ Â· æ²ˆæ´ºå¼˜</p>
                </div>
                <div style="text-align: right;">
                    <p style="margin-bottom: 8px; font-size: 1.1em;"><strong>ğŸ”— é¡¹ç›®èµ„æº</strong></p>
                    <p style="opacity: 0.9;">
                        <a href="https://github.com/wuxinwuwen" style="color: #4D96FF; text-decoration: none; font-weight: 600; display: inline-flex; align-items: center; gap: 8px;">
                            <span>GitHub Repository</span>
                            <span style="font-size: 1.2em;">â†—</span>
                        </a>
                    </p>
                </div>
            </div>
        </div>
        """)

        # UIäº¤äº’é€»è¾‘
        task_type.change(
            fn=toggle_ref_text_visibility,
            inputs=task_type,
            outputs=ref_text_input
        )

        model_type.change(
            fn=toggle_adapter_path_visibility,
            inputs=model_type,
            outputs=adapter_path_input
        )

        model_type.change(
            fn=get_model_status,
            inputs=[model_type, adapter_path_input],
            outputs=model_status
        )

        adapter_path_input.change(
            fn=get_model_status,
            inputs=[model_type, adapter_path_input],
            outputs=model_status
        )

        check_model_btn.click(
            fn=get_model_status,
            inputs=[model_type, adapter_path_input],
            outputs=model_status
        )

        submit_btn.click(
            fn=process_ocr_task,
            inputs=[file_input, model_size, task_type, ref_text_input, model_type, adapter_path_input],
            outputs=[performance_output, output_text, output_gallery]
        )

        clear_btn.click(
            fn=lambda: [None, """
            **ç³»ç»ŸçŠ¶æ€**: <span class='status-indicator status-ready'></span> å·²é‡ç½®å°±ç»ª

            ### ğŸ¯ ç³»ç»Ÿå·²é‡ç½®
            - æ‰€æœ‰è¾“å…¥å·²æ¸…ç©º
            - ç»“æœåŒºåŸŸå·²é‡ç½®
            - ç­‰å¾…æ–°çš„æ–‡ä»¶ä¸Šä¼ 

            ### ğŸ’¡ å‡†å¤‡å°±ç»ª
            è¯·é€‰æ‹©æ¨¡å‹ç±»å‹å¹¶ä¸Šä¼ æ–°çš„å›¾åƒæˆ–PDFæ–‡ä»¶å¼€å§‹å¤„ç†
            """, "", []],
            inputs=[],
            outputs=[file_input, performance_output, output_text, output_gallery]
        )

    return demo


def main() -> None:
    """åˆå§‹åŒ–å’Œå¯åŠ¨åº”ç”¨ç¨‹åºçš„ä¸»å‡½æ•°"""
    # æ£€æŸ¥å¾®è°ƒæ¨¡å‹çŠ¶æ€
    finetuned_model_exists = check_finetuned_model_exists("./final_model")

    if finetuned_model_exists:
        print("âœ… å¾®è°ƒæ¨¡å‹å·²å°±ç»ªï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨")
    else:
        print("âš ï¸ å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨æˆ–æ–‡ä»¶ä¸å®Œæ•´ï¼Œè¯·ä½¿ç”¨åŸå§‹æ¨¡å‹")

    # å¦‚æœç¤ºä¾‹ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
    if not os.path.exists("examples"):
        os.makedirs("examples")
        print("âœ… åˆ›å»ºäº†examplesç›®å½•ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤æ”¾ç½®ç¤ºä¾‹æ–‡ä»¶")

    # è·å–å¯ç”¨ç«¯å£
    available_port = get_available_port()
    print(f"ğŸ” æ£€æµ‹åˆ°å¯ç”¨ç«¯å£: {available_port}")

    # åˆ›å»ºå¹¶å¯åŠ¨UI
    demo = create_ui()

    print("ğŸš€ æ­£åœ¨å¯åŠ¨DeepSeek-OCRæœåŠ¡...")
    print("ğŸ¨ ç°ä»£åŒ–UIç•Œé¢å·²åŠ è½½")
    print("ğŸ¤– æ”¯æŒåŠŸèƒ½:")
    print("   - åŸå§‹DeepSeek-OCRæ¨¡å‹")
    print("   - å¾®è°ƒæ¨¡å‹ (LoRAé€‚é…å™¨)")
    print("   - æ™ºèƒ½æ¨¡å‹åˆ‡æ¢")
    print("   - å®æ—¶æ€§èƒ½ç›‘æ§")
    print("   - PDFå¤šé¡µå¤„ç†")
    print("ğŸ“ å¦‚æœæ— æ³•è®¿é—®ï¼Œè¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š")
    print("   1. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
    print("   2. å°è¯•ä½¿ç”¨ http://localhost:7860")
    print("   3. ç¡®ä¿æ²¡æœ‰å…¶ä»–ç¨‹åºå ç”¨7860ç«¯å£")
    print("   4. å°è¯•é‡å¯åº”ç”¨ç¨‹åº")

    try:
        demo.queue(max_size=20).launch(
            server_name="0.0.0.0",
            server_port=available_port,
            share=False,
            show_error=True,
            inbrowser=True,
            quiet=False,
            debug=True
        )
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ”„ å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®...")
        demo.queue(max_size=20).launch(
            server_name="127.0.0.1",
            server_port=available_port,
            share=False,
            show_error=True,
            inbrowser=True
        )


if __name__ == "__main__":
    main()